{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP9418 - Assignment 1 - Bayesian Networks as Classifiers\n",
    "\n",
    "## UNSW Sydney, October 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical prerequisites\n",
    "\n",
    "These are the libraries your are allowed to use. No other libraries will be accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make division default to floating-point, saving confusion\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Allowed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import heapq as pq\n",
    "import matplotlib as mp\n",
    "import math\n",
    "from itertools import product, combinations\n",
    "from collections import OrderedDict as odict\n",
    "from graphviz import Digraph\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial task - Initialise graph\n",
    "\n",
    "Create a graph ``G`` that represents the following network by filling in the edge lists.\n",
    "![Bayes Net](BayesNet.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = {\n",
    "    \"BreastDensity\" : ['Mass'],\n",
    "    \"Location\" : ['BC'],\n",
    "    \"Age\" : ['BC'],\n",
    "    \"BC\" : ['MC','SkinRetract','NippleDischarge','AD','Mass','Metastasis'],\n",
    "    \"Mass\" : ['Size','Shape','Margin'],\n",
    "    \"AD\" : ['FibrTissueDev'],\n",
    "    \"Metastasis\" : ['LymphNodes'],\n",
    "    \"MC\" : [],\n",
    "    \"Size\" : [],\n",
    "    \"Shape\" : [],\n",
    "    \"FibrTissueDev\" : ['Spiculation', 'SkinRetract', 'NippleDischarge'],\n",
    "    \"LymphNodes\" : [],\n",
    "    \"SkinRetract\" : [],\n",
    "    \"NippleDischarge\" : [],\n",
    "    \"Spiculation\" : ['Margin'],\n",
    "    \"Margin\" : [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G: node --> child graph\n",
    "# G_p: node --> parent graph\n",
    "def find_parents(G):\n",
    "    G_p={}\n",
    "    for node in G:\n",
    "        G_p[node]=[]\n",
    "    for node in G:\n",
    "        for c_node in G[node]:\n",
    "            G_p[c_node].append(node)\n",
    "    return G_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G_p = find_parents(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [20 Marks] Task 1 - Efficient d-separation test\n",
    "\n",
    "Implement the efficient version of the d-separation algorithm in a function ``d_separation(G, X, Z, Y)`` that return a boolean: true if **X** is d-separated from **Y** given **Z** in the graph $G$ and false otherwise.\n",
    "\n",
    "* **X**,**Y** and **Z** are python sets, each containing a set of variable names. \n",
    "* Variable names may be strings or integers, and can be assumed to be nodes of the graph $G$. \n",
    "* $G$ is a graph as defined in tutorial 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop your code for d_separation(G, X, Z, Y) in one or more cells here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using bfs to find whether there is a way from X to Y\n",
    "# G is a no direction graph. Both current node's parents and children need to be added in.\n",
    "\n",
    "def BFS(G, G_p, X, Y):\n",
    "    searched = []\n",
    "    while True:\n",
    "        if not X:\n",
    "            break\n",
    "        x_node=X.pop()\n",
    "        searched.append(x_node)\n",
    "        if x_node in Y:\n",
    "            return False\n",
    "        else:\n",
    "            for node in G[x_node]:\n",
    "                if node not in searched:\n",
    "                    X.append(node)\n",
    "            for node in G_p[x_node]:\n",
    "                if node not in searched:\n",
    "                    X.append(node)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_separation(G, X, Z, Y):\n",
    "    \n",
    "    G_p=find_parents(G)\n",
    "    \n",
    "    # Generate a new DAG G_new\n",
    "    G_new={}\n",
    "    \n",
    "    # Find all leaf nodes from G if they are not belong to X, Y and Z\n",
    "    leaf_nodes=[]\n",
    "    for val in G:\n",
    "        if not G[val] and val not in X and val not in Y and val not in Z:\n",
    "            leaf_nodes.append(val)\n",
    "    \n",
    "    # Delete all leaf nodes\n",
    "    # Delete all edges outgoing from nodes in Z\n",
    "    \n",
    "    for val in G:\n",
    "        if val not in leaf_nodes:\n",
    "            G_new[val]=[]\n",
    "            if val in Z:\n",
    "                pass\n",
    "            else:\n",
    "                for value in G[val]:\n",
    "                    if value not in leaf_nodes:\n",
    "                        G_new[val].append(value)\n",
    "        \n",
    "    return BFS(G_new, G_p, list(X), list(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n",
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "def test(statement):\n",
    "    if statement:\n",
    "        print(\"Passed test case\")\n",
    "    else:\n",
    "        print(\"Failed test case\")\n",
    "        \n",
    "test(d_separation(G, set(['Age']), set(['BC']), set(['AD'])))\n",
    "test(not d_separation(G, set(['Spiculation','LymphNodes']), set(['MC', 'Size']), set(['Age'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [10 Marks] Task 2 - Estimate Bayesian Network parameters from data\n",
    "\n",
    "Implement a function ``learn_outcome_space(data)`` that learns the outcome space (the valid values for each variable) from the pandas dataframe ``data`` and returns a dictionary ``outcomeSpace`` with these values.\n",
    "\n",
    "Implement a function ``learn_bayes_net(G, data, outcomeSpace)`` that learns the parameters of the Bayesian Network $G$. This function should return a dictionary ``prob_tables`` with the all conditional probability tables (one for each node).\n",
    "\n",
    "- ``G`` is a directed acyclic graph. For this part of the assignment, $G$ should be declared according to the breast cancer Bayesian network presented in the diagram in the assignment specification.\n",
    "- ``data`` is a dataframe created from a csv file containing the relevant data. \n",
    "- ``outcomeSpace`` is defined in tutorials.\n",
    "- ``prob_tables`` is a dict from each variable name (node) to a \"factor\". Factors are defined in tutorial 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for learn_outcome_space(data) in one or more cells here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_outcome_space(data):\n",
    "    head_name=list(data.columns)\n",
    "    outcomspace={}\n",
    "    for var in head_name:\n",
    "        outcomspace[var]=set(data[var])\n",
    "    return outcomspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "with open('bc.csv') as file:\n",
    "    data = pd.read_csv(file)\n",
    "\n",
    "outcomeSpace = learn_outcome_space(data)\n",
    "\n",
    "outcomes = outcomeSpace['BreastDensity']\n",
    "answer = ('high', 'medium', 'low')\n",
    "test(len(outcomes) == len(answer) and set(outcomes) == set(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for learn_bayes_net(G, data, outcomeSpace) in one or more cells here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_prob(node, G_p, data):\n",
    "    \n",
    "    # find nodes in factor\n",
    "    world = [node]+G_p[node]\n",
    "    df = pd.DataFrame(data.groupby(world).size(), columns=['num'])\n",
    "    \n",
    "    # if the node has no parents\n",
    "    if not G_p[node]:\n",
    "        df['num'] = df['num']/df['num'].sum()\n",
    "        d = {}\n",
    "        d['dom'] = tuple(df.index.names)\n",
    "        d['table'] = odict()\n",
    "        for x in df.index:\n",
    "            x_1 = (x, )\n",
    "            d['table'][x_1] = df.loc[x, 'num']\n",
    "            \n",
    "    # if the node have parents\n",
    "    else:\n",
    "        d = {}\n",
    "        d['table'] = odict()\n",
    "        df2 = df.sum(level=G_p[node])\n",
    "        df3 = pd.merge(df, df2, left_index=True, right_index=True)\n",
    "        df3['num']=df3['num_x']/df3['num_y']\n",
    "        d['dom'] = tuple(df3.index.names)\n",
    "        for x in df3.index:\n",
    "            d['table'][x] = df3.loc[x, 'num']\n",
    "\n",
    "    return  d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_bayes_net(G, data, outcomeSpace):\n",
    "    G_p = find_parents(G)\n",
    "    prob_tables = {}\n",
    "    for node in G:\n",
    "        d = condition_prob(node, G_p, data)\n",
    "        prob_tables[node] = d\n",
    "    return prob_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "prob_tables = learn_bayes_net(G, data, outcomeSpace)\n",
    "test(abs(prob_tables['Age']['table'][('35-49',)] - 0.2476) < 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [20 Marks] Task 3 - Bayesian Network Classification\n",
    "\n",
    "Design a new function ``assess_bayes_net(G, prob_tables, data, outcomeSpace, class_var)`` that uses the test cases in ``data`` to assess the performance of the Bayesian network defined by ``G`` and ``prob_tables``. Implement the efficient classification procedure discussed in the lectures. Such a function should return the classifier accuracy. \n",
    " * ``class_var`` is the name of the variable you are predicting, using all other variables.\n",
    " * ``outcomeSpace`` was created in task 2\n",
    " \n",
    "Remember to remove the variables ``metastasis`` and ``lymphnodes`` from the dataset before assessing the accuracy.\n",
    "\n",
    "Return just the accuracy:\n",
    "\n",
    "``acc = assess_bayes_net(G, prob_tables, data, outcomeSpace, class_var)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the variables metastasis and lymphnodes from G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new G\n",
    "def G_remove(G, remove_list):\n",
    "    G_r = copy.deepcopy(G)\n",
    "    for x in G:\n",
    "        if x in remove_list:\n",
    "            G_r.pop(x)\n",
    "        else:\n",
    "            for y in G[x]:\n",
    "                if y in remove_list:\n",
    "                    G_r[x].remove(y)\n",
    "    return G_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new outcomespace\n",
    "def outcomeSpace_remove(outcomeSpace, remove_list):\n",
    "    outcomeSpace_r = outcomeSpace.copy()\n",
    "    for node in outcomeSpace:\n",
    "        if node in remove_list:\n",
    "            outcomeSpace_r.pop(node)\n",
    "    return outcomeSpace_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new data\n",
    "def data_remove(data, remove_list):\n",
    "    data_r =copy.deepcopy(data)\n",
    "    for x in remove_list:\n",
    "        if x in list(data.columns):\n",
    "            data_r.drop(columns=x, inplace=True)\n",
    "    return data_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 'Metastasis' and 'LymphNodes' \n",
    "remove_list = ['Metastasis','LymphNodes']\n",
    "G = G_remove(G, remove_list)\n",
    "outcomeSpace = outcomeSpace_remove(outcomeSpace, remove_list)\n",
    "data = data_remove(data, remove_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop your code for assess_bayes_net(G, prob_tables, data, outcomeSpace, class_var) in one or more cells here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob and join functions are from tutorial 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob(factor, *entry):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `factor`, a dictionary of domain and probability values,\n",
    "    `entry`, a list of values, one for each variable in the same order as specified in the factor domain.\n",
    "    \n",
    "    Returns p(entry)\n",
    "    \"\"\"\n",
    "    if entry in factor['table']:\n",
    "        return factor['table'][entry]\n",
    "    return 0     # insert your code here, 1 line    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join(f1, f2, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f1`, first factor to be joined.\n",
    "    `f2`, second factor to be joined.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "    \n",
    "    Returns a new factor with a join of f1 and f2\n",
    "    \"\"\"\n",
    "    \n",
    "    # First, we need to determine the domain of the new factor. It will be union of the domain in f1 and f2\n",
    "    # But it is important to eliminate the repetitions\n",
    "    common_vars = list(f1['dom']) + list(set(f2['dom']) - set(f1['dom']))\n",
    "    \n",
    "    # We will build a table from scratch, starting with an empty list. Later on, we will transform the list into a odict\n",
    "    table = list()\n",
    "    \n",
    "    # Here is where the magic happens. The product iterator will generate all combinations of varible values \n",
    "    # as specified in outcomeSpace. Therefore, it will naturally respect observed values\n",
    "    for entries in product(*[outcomeSpace[node] for node in common_vars]):\n",
    "        \n",
    "        # We need to map the entries to the domain of the factors f1 and f2\n",
    "        entryDict = dict(zip(common_vars, entries))\n",
    "        f1_entry = (entryDict[var] for var in f1['dom'])\n",
    "        f2_entry = (entryDict[var] for var in f2['dom'])\n",
    "        \n",
    "        # Insert your code here\n",
    "        p1 = prob(f1, *f1_entry)           # Use the fuction prob to calculate the probability in factor f1 for entry f1_entry \n",
    "        p2 = prob(f2, *f2_entry)           # Use the fuction prob to calculate the probability in factor f2 for entry f2_entry \n",
    "        \n",
    "        # Create a new table entry with the multiplication of p1 and p2\n",
    "        table.append((entries, p1 * p2))\n",
    "    return {'dom': tuple(common_vars), 'table': odict(table)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find Markov blanket\n",
    "# return {'parent': parent, 'child': child, 'spouse': spouse, 'node': current_node}\n",
    "\n",
    "def find_M_blanket(G, G_p, class_var):\n",
    "    blanket = {}\n",
    "    blanket['node'] = [class_var]\n",
    "    \n",
    "    # add children and parents\n",
    "    blanket['child'] = G[class_var]\n",
    "    blanket['parent'] = G_p[class_var]\n",
    "    \n",
    "    # add spouses\n",
    "    spouses = []\n",
    "    for node in G[class_var]:\n",
    "            spouses = spouses + G_p[node]\n",
    "    blanket['spouse'] = list(set(spouses))\n",
    "    blanket['spouse'].remove(class_var)\n",
    "    \n",
    "    return blanket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate joint table of all nodes in M_blanket\n",
    "\n",
    "def all_world(train_net, outcomeSpace, M_blanket):\n",
    "    join_order = []\n",
    "    # from children but not spouses\n",
    "    for child in M_blanket['child']:\n",
    "        if child not in M_blanket['spouse']:\n",
    "            join_order.append(child)\n",
    "    \n",
    "    # node\n",
    "    join_order.append(M_blanket['node'][0])\n",
    "    \n",
    "    # spouses\n",
    "    for spouse in M_blanket['spouse']:\n",
    "        join_order.append(spouse)\n",
    "    \n",
    "    # parents\n",
    "    for parents in M_blanket['parent']:\n",
    "        join_order.append(parents)\n",
    "    \n",
    "    # join all nodes in order\n",
    "    if len(join_order)<2:\n",
    "        return train_net\n",
    "    else:\n",
    "        prob_table = train_net[join_order[0]]\n",
    "        for i in range(1, len(join_order)):\n",
    "            prob_table = join(prob_table, train_net[join_order[i]], outcomeSpace)\n",
    "            \n",
    "    return prob_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(evidence, joint_table, class_var, outcomeSpace):\n",
    "    all_v = list(outcomeSpace[class_var])\n",
    "    res = all_v[0]\n",
    "    p = 0\n",
    "    for x in all_v:\n",
    "        evidence[class_var] = x\n",
    "        temp = joint_table['table'][tuple(evidence)]\n",
    "        if temp > p:\n",
    "            res = x\n",
    "            p = temp\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_acc(class_var, e, prob_table, outcomeSpace):\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for n in range(len(e)):\n",
    "        t = e.iloc[n].copy(deep = True)\n",
    "        if predict(t, prob_table, class_var, outcomeSpace)==e[class_var][n]:\n",
    "            i = i + 1\n",
    "        else:\n",
    "            j = j + 1\n",
    "    return i/(i+j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_bayes_net(G, prob_tables, test_df, outcomeSpace, class_var):\n",
    "    G_p = find_parents(G)\n",
    "    M_blanket = find_M_blanket(G, G_p, class_var)\n",
    "    joint_table = all_world(prob_tables, outcomeSpace, M_blanket)\n",
    "    e = test_df[list(joint_table['dom'])]\n",
    "    return predict_acc(class_var, e, joint_table, outcomeSpace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8395"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "# removed nodes\n",
    "k = 10\n",
    "l = len(data)\n",
    "n = 0\n",
    "test_data = data.iloc[n*l//k:(n+1)*l//k]\n",
    "train_data = data.drop(data.index[n*l//k:(n+1)*l//k])\n",
    "test_data = test_data.reset_index(drop = True)\n",
    "\n",
    "\n",
    "train_prob_tables = learn_bayes_net(G, train_data, outcomeSpace)\n",
    "\n",
    "#acc = assess_bayes_net(G, prob_tables, data, outcomeSpace, class_var)\n",
    "assess_bayes_net(G, train_prob_tables, test_data, outcomeSpace, 'BC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop a function ``cv_bayes_net(G, data, class_var)`` that uses ``learn_outcome_space``, ``learn_bayes_net``and ``assess_bayes_net`` to learn and assess a Bayesian network in a dataset using 10-fold cross-validation. Compute and report the average accuracy over the ten cross-validation runs as well as the standard deviation, e.g.\n",
    "\n",
    "``acc, stddev = cv_bayes_net(G, data, class_var)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for cv_bayes_net(G, data, class_var) in one or more cells here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_bayes_net(G, data, class_var):\n",
    "    \n",
    "    acc_list = []\n",
    "    \n",
    "    k = 10\n",
    "    l = len(data)\n",
    "    \n",
    "    for n in range(k):\n",
    "    \n",
    "        # split train and test data sets\n",
    "        test_data = data.iloc[n*l//k:(n+1)*l//k]\n",
    "        train_data = data.drop(data.index[n*l//k:(n+1)*l//k])\n",
    "        test_data = test_data.reset_index(drop = True)\n",
    "\n",
    "        train_prob_tables = learn_bayes_net(G, train_data, outcomeSpace)\n",
    "        \n",
    "        acc_list.append(assess_bayes_net(G, train_prob_tables, test_data, outcomeSpace, class_var))\n",
    "        \n",
    "    acc_Series = pd.Series(acc_list)\n",
    "    \n",
    "    return acc_Series.mean(), acc_Series.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8411, 0.006208417225383976)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "# removed\n",
    "acc, stddev = cv_bayes_net(G, data, 'BC')\n",
    "acc, stddev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [10 Marks] Task 4 - Na√Øve Bayes Classification\n",
    "\n",
    "Design a new function ``assess_naive_bayes(G, prob_tables, data, outcomeSpace, class_var)`` to classify and assess the test cases in a dataset ``data`` according to the Na√Øve Bayes classifier. To classify each example, use the log probability trick discussed in the lectures. This function should return the accuracy of the classifier in ``data``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for assess_naive_bayes(G, prob_tables, data, outcomeSpace, class_var) in one or more cells here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_naive_bayes(G, prob_tables, data, outcomeSpace, class_var):\n",
    "    i = 0\n",
    "    for n in range(len(data)):\n",
    "        evidence = data.iloc[n]\n",
    "        res = predict_naive(evidence, prob_tables, class_var)\n",
    "        if res == evidence[class_var]:\n",
    "            i = i + 1\n",
    "    return i/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7875"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "#  please compile all functions in this task first\n",
    "\n",
    "k = 10\n",
    "l = len(data)\n",
    "n = 0\n",
    "G_p = find_parents(G)\n",
    "test_data = data.iloc[n*l//k:(n+1)*l//k]\n",
    "train_data = data.drop(data.index[n*l//k:(n+1)*l//k])\n",
    "test_data = test_data.reset_index(drop = True)\n",
    "\n",
    "naive_graph = learn_naive_bayes_structure(outcomeSpace, 'BC')\n",
    "naive_net = learn_bayes_net(naive_graph, train_data, outcomeSpace)\n",
    "\n",
    "\n",
    "\n",
    "acc = assess_naive_bayes(naive_graph, naive_net, test_data, outcomeSpace, 'BC')\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop a new function ``cv_naive_bayes(data, class_var)`` that uses ``assess_naive_bayes`` to assess the performance of the Na√Øve Bayes classifier in a dataset ``data``. To develop this code, perform the following steps:\n",
    "\n",
    "1. Use 10-fold cross-validation to split the data into training and test sets.\n",
    "\n",
    "2. Implement a function ``learn_naive_bayes_structure(outcomeSpace, class_var)`` to create and return a Na√Øve Bayes graph structure from ``outcomeSpace`` and ``class_var``. \n",
    "\n",
    "3. Use ``learn_bayes_net(G, data, outcomeSpace)`` to learn the Na√Øve Bayes parameters from a training set ``data``. \n",
    "\n",
    "4. Use ``assess_naive_bayes(G, prob_tables, data, outcomeSpace, class_var)`` to compute the accuracy of the Na√Øve Bayes classifier in a test set ``data``. Remember to remove the variables ``metastasis`` and ``lymphnodes`` from the dataset before assessing the accuracy.\n",
    "\n",
    "Do 10-fold cross-validation, same as above, and return ``acc`` and ``stddev``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for learn_naive_bayes_structure(outcomeSpace, class_var) in one or more cells here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_naive_bayes_structure(outcomeSpace, class_var):\n",
    "    naive_G = {}\n",
    "    naive_G[class_var] = []\n",
    "    for node in outcomeSpace:\n",
    "        if node != class_var:\n",
    "            naive_G[class_var].append(node)\n",
    "            naive_G[node] = []\n",
    "    return naive_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "naive_graph = learn_naive_bayes_structure(outcomeSpace, 'BC')\n",
    "#naive_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_naive(evidence, naive_net, class_var):\n",
    "    post = {}\n",
    "    for prior in naive_net[class_var]['table']:\n",
    "        posterior = 0\n",
    "        for node in naive_net:\n",
    "                if node == class_var:\n",
    "                    posterior = posterior + math.log(naive_net[class_var]['table'][prior])\n",
    "                else:\n",
    "                    likelihood = tuple()\n",
    "                    for x in naive_net[node]['dom']:\n",
    "                        if x == class_var:\n",
    "                            likelihood = likelihood + prior\n",
    "                        else:\n",
    "                            likelihood = likelihood + (evidence[x], )\n",
    "                    try:\n",
    "                        posterior = posterior + math.log(naive_net[node]['table'][likelihood])\n",
    "                    except KeyError:\n",
    "                        posterior = posterior + math.log(1/20000)\n",
    "                    else:\n",
    "                        pass\n",
    "        post[prior] = posterior\n",
    "    return max(zip(post.values(),post.keys()))[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for cv_naive_bayes(data, class_var) in one or more cells here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_naive_bayes(data, class_var):\n",
    "    outcomeSpace = learn_outcome_space(data)\n",
    "    naive_graph = learn_naive_bayes_structure(outcomeSpace, class_var)\n",
    "    \n",
    "\n",
    "    acc_list = []\n",
    "    \n",
    "    k = 10\n",
    "    l = len(data)\n",
    "    \n",
    "    for n in range(k):\n",
    "    \n",
    "        # split train and test data sets\n",
    "        test_data = data.iloc[n*l//k:(n+1)*l//k]\n",
    "        train_data = data.drop(data.index[n*l//k:(n+1)*l//k])\n",
    "        test_data = test_data.reset_index(drop = True)\n",
    "        \n",
    "        naive_net = learn_bayes_net(naive_graph, train_data, outcomeSpace)\n",
    "        \n",
    "        acc_list.append(assess_naive_bayes(naive_graph, naive_net, test_data, outcomeSpace, class_var))\n",
    "        \n",
    "    acc_Series = pd.Series(acc_list)\n",
    "    \n",
    "    return acc_Series.mean(), acc_Series.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "acc, stddev = cv_naive_bayes(data, 'BC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7919, 0.009103723292026066)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, stddev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [20 Marks] Task 5 - Tree-augmented Na√Øve Bayes Classification\n",
    "\n",
    "Similarly to the previous task, implement a Tree-augmented Na√Øve Bayes (TAN) classifier and evaluate your implementation in the breast cancer dataset. Design a function ``learn_tan_structure(data, outcomeSpace, class_var)`` to learn the TAN structure (graph) from the ``data`` and returns such a structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for learn_tan_structure(data, outcomeSpace, class_var) in one or more cells here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results for P(ùê¥ùëñ|C)\n",
    "# In this case, all attributs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TAN_condition_prob(node, data, class_var):\n",
    "    world = [node] + [class_var]\n",
    "    df = pd.DataFrame(data.groupby(world).size(), columns=['num'])\n",
    "\n",
    "    d = {}\n",
    "    d['table'] = odict()\n",
    "    df2 = df.sum(level=class_var)\n",
    "    df3 = pd.merge(df, df2, left_index=True, right_index=True)\n",
    "    df3['num']=df3['num_x']/df3['num_y']\n",
    "    d['dom'] = tuple(df3.index.names)\n",
    "    for x in df3.index:\n",
    "        d['table'][x] = df3.loc[x, 'num']\n",
    "    \n",
    "    return  d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAN_condition_prob('Age', data, 'BC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TAN_con_table(outcomeSpace, data, class_var): \n",
    "    con_tables = {}\n",
    "    for node in outcomeSpace:\n",
    "        if node != class_var:\n",
    "            d = TAN_condition_prob(node,data, class_var)\n",
    "            con_tables[node] = d\n",
    "    return con_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAN_con_table(outcomeSpace, data, 'BC').keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the probability P(ùê¥ùëñ, ùê¥ùëó|C) for each two attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TAN_join_condition_prob(node_i, node_j, data, class_var):\n",
    "    world = [node_i] + [node_j] + [class_var]\n",
    "    df = pd.DataFrame(data.groupby(world).size(), columns=['num'])\n",
    "    \n",
    "    d = {}\n",
    "    d['table'] = odict()\n",
    "    df2 = df.sum(level=class_var)\n",
    "    df3 = pd.merge(df, df2, left_index=True, right_index=True)\n",
    "    df3['num']=df3['num_x']/df3['num_y']\n",
    "    d['dom'] = tuple(df3.index.names)\n",
    "    for x in df3.index:\n",
    "        d['table'][x] = df3.loc[x, 'num']\n",
    "    \n",
    "    return  d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_con_table(outcomeSpace, data, class_var): \n",
    "    con_tables = {}\n",
    "    for node_i in outcomeSpace:\n",
    "        for node_j in outcomeSpace:\n",
    "            if node_i != class_var and node_j != class_var and node_i != node_j:\n",
    "                d = TAN_join_condition_prob(node_i, node_j, data, class_var)\n",
    "                con_tables[(node_i, node_j)] = d\n",
    "    return con_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jct = join_con_table(outcomeSpace, data, 'BC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the probability of each value of the class variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_class(data, outcomeSpace, class_var):\n",
    "    var = outcomeSpace\n",
    "    copy_data=data.copy()\n",
    "    prob_class={}\n",
    "    for v in var[class_var]:\n",
    "        v_data = copy_data.loc[copy_data[class_var]==v]\n",
    "        prob_class[v] = len(v_data)/len(copy_data)\n",
    "    return prob_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the probability P(ùê¥ùëñ,ùê¥ùëó,C) for each two attributes \n",
    "# Using P(ùê¥ùëñ,ùê¥ùëó,C) = P(ùê¥ùëñ,ùê¥ùëó|C)*P(C) to get the probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TAN_join_prob(data, outcomeSpace, join_prob, class_var):\n",
    "    var = outcomeSpace\n",
    "    join_res = {}\n",
    "    #join_prob = join_con_table(outcomeSpace, data, class_var)\n",
    "    class_var_prob = pd.DataFrame(data.groupby('BC').size()/len(data), columns=['num']).to_dict()['num']\n",
    "    for k in join_prob.keys():\n",
    "        for key in join_prob[k]['table'].keys():\n",
    "            for v in var[class_var]:\n",
    "                if v in key:\n",
    "                    join_res[key] = join_prob[k]['table'][key] * class_var_prob[v]\n",
    "    return join_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mutual information for every two attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MI_TAN(data, outcomeSpace, class_var):\n",
    "    MI = {}\n",
    "    prob_aic = TAN_con_table(outcomeSpace, data, class_var)\n",
    "    prob_con_aiajc = join_con_table(outcomeSpace, data, class_var)\n",
    "    prob_join_aiajc = TAN_join_prob(data, outcomeSpace, prob_con_aiajc, class_var)\n",
    "    for i in outcomeSpace:\n",
    "        for j in outcomeSpace:\n",
    "            sum_MI = 0\n",
    "            if i != j and i != class_var and j != class_var:                \n",
    "                s = prob_con_aiajc[(i, j)]['table'].keys()\n",
    "                l = prob_aic[i]['table'].keys()\n",
    "                r = prob_aic[j]['table'].keys()\n",
    "                u = prob_join_aiajc.keys()\n",
    "                for v1 in l:\n",
    "                    for v2 in r:\n",
    "                        for v in s:\n",
    "                            if v1[0] == v[0] and v2[0] == v[1] and v1[1] == v2[1] and v1[1] == v[2]:\n",
    "                                ai = prob_aic[i]['table'][(v1[0], v1[1])]\n",
    "                                aj = prob_aic[j]['table'][(v2[0], v1[1])]\n",
    "                                aiaj = prob_con_aiajc[(i, j)]['table'][(v[0], v[1], v[2])]\n",
    "                                aiajc = prob_join_aiajc[(v[0], v[1], v[2])]\n",
    "                                \n",
    "                                temp = aiaj / (ai * aj)\n",
    "                                t = math.log(temp) * aiajc\n",
    "                sum_MI += t\n",
    "                                \n",
    "            MI[(i, j)] = round(sum_MI, 15)\n",
    "    return MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MI_TAN(data, outcomeSpace, 'BC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TAN_matrix(outcomeSpace, class_var):\n",
    "    TANmatrix = {}\n",
    "    for row in outcomeSpace:\n",
    "        TANmatrix[row] = {}\n",
    "        for col in outcomeSpace:\n",
    "            TANmatrix[row][col] = 0\n",
    "    return TANmatrix\n",
    "\n",
    "# UPDATE MATRIX WITH WEIGHT w\n",
    "def updateWeight(data, outcomeSpace, class_var):\n",
    "    TANmatrix = TAN_matrix(outcomeSpace, class_var)\n",
    "    MI_D = MI_TAN(data, outcomeSpace, class_var)\n",
    "    for x in outcomeSpace:\n",
    "        for y in outcomeSpace:\n",
    "            if x != y and x != class_var and y != class_var:\n",
    "                TANmatrix[x][y] = MI_D[(x, y)]\n",
    "            elif x == y:\n",
    "                pass\n",
    "    return TANmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#updateWeight(data, outcomeSpace, 'BC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the maximum spanning tree with the mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_spanning_tree(data, outcomeSpace, class_var):\n",
    "    G_MI = updateWeight(data, outcomeSpace, class_var)\n",
    "    # generate a node dict\n",
    "    new_d = {}\n",
    "    for x in G_MI:\n",
    "        if x != class_var:\n",
    "            new_d[x]=[]\n",
    "            for y in G_MI[x]:\n",
    "                if y != class_var and y !=x:\n",
    "                    new_d[x].append((x,y,G_MI[x][y]))\n",
    "    \n",
    "    # maximum spanning tree\n",
    "    candidate = []\n",
    "    selected = [x for x in new_d]\n",
    "    tree_d = {}\n",
    "    node = selected.pop()\n",
    "    candidate.append(node)\n",
    "    tree_d[node] = new_d[node]\n",
    "    \n",
    "    G = []\n",
    "    while True:\n",
    "        if len(candidate) == len(new_d):\n",
    "            break\n",
    "        #print(candidate)\n",
    "        s = []\n",
    "        for x in candidate:\n",
    "            s = s + tree_d[x]\n",
    "        s.sort(key = lambda x: x[2], reverse=True)\n",
    "        #print(s)\n",
    "        for i in s:\n",
    "            if i[0] in tree_d and i[1] in tree_d:\n",
    "                pass\n",
    "            else:\n",
    "                m = i\n",
    "                tree_d[m[0]].remove(m)\n",
    "                tree_d[m[1]] = new_d[m[1]]\n",
    "                G.append(m)\n",
    "                candidate.append(m[1])\n",
    "                break\n",
    "                \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_tan_structure(data, outcomeSpace, class_var):\n",
    "    MST = max_spanning_tree(data, outcomeSpace, class_var)\n",
    "    g_t = []\n",
    "    g_t_dict = {}\n",
    "    class_list = []\n",
    "    for key in MST:\n",
    "        g_t.append((key[0], key[1]))\n",
    "    keys = []\n",
    "    values = []\n",
    "    for val in g_t:\n",
    "        if val[0] not in keys:\n",
    "            g_t_dict[val[0]] = [val[1]]\n",
    "        else:\n",
    "            g_t_dict[val[0]].append(val[1])\n",
    "        keys.append(val[0])\n",
    "    for val in outcomeSpace:\n",
    "        if val != class_var:\n",
    "            class_list.append(val)\n",
    "    g_t_dict[class_var] = class_list\n",
    "    for i in outcomeSpace:\n",
    "        if i not in keys and i != class_var:\n",
    "            g_t_dict[i] = []\n",
    "    return g_t_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n",
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "tan_graph = learn_tan_structure(data, outcomeSpace, 'BC')\n",
    "test(len(tan_graph['BC']) == len(tan_graph)-1)\n",
    "test('FibrTissueDev' in tan_graph['Spiculation'] or 'Spiculation' in tan_graph['FibrTissueDev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tan_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the other tasks, design a function ``cv_tan(data, class_var)`` that uses 10-fold cross-validation to assess the performance of the TAN classifier from ``data``. Remember to remove the variables ``metastasis`` and ``lymphnodes`` from the dataset before assessing the accuracy. This function should use the ``learn_tan_structure`` as well as other functions defined in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for cv_tan(data, class_var) in one or more cells here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_tan(data, class_var):\n",
    "    outcomeSpace = learn_outcome_space(data)\n",
    "    tan_graph = learn_tan_structure(data, outcomeSpace, class_var)\n",
    "\n",
    "    acc_list = []\n",
    "    \n",
    "    k = 10\n",
    "    l = len(data)\n",
    "    \n",
    "    for n in range(k):\n",
    "    \n",
    "        # split train and test data sets\n",
    "        test_data = data.iloc[n*l//k:(n+1)*l//k]\n",
    "        train_data = data.drop(data.index[n*l//k:(n+1)*l//k])\n",
    "        test_data = test_data.reset_index(drop = True)\n",
    "        \n",
    "        tan_net = learn_bayes_net(tan_graph, train_data, outcomeSpace)\n",
    "        \n",
    "        acc_list.append(assess_naive_bayes(tan_graph, tan_net, test_data, outcomeSpace, class_var))\n",
    "        \n",
    "    acc_Series = pd.Series(acc_list)\n",
    "    \n",
    "    return acc_Series.mean(), acc_Series.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "acc, stddev = cv_tan(data, 'BC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8374499999999999, 0.006946022043027375)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, stddev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [20 Marks] Task 6 - Report\n",
    "\n",
    "Write a report (**with less than 500 words**) summarising your findings in this assignment. Your report should address the following:\n",
    "\n",
    "a. Make a summary and discussion of the experimental results (accuracy). Use plots to illustrate your results.\n",
    "\n",
    "b. Discuss the complexity of the implemented algorithms.\n",
    "\n",
    "Use Markdown and Latex to write your report in the Jupyter notebook. Develop some plots using Matplotlib to illustrate your results. Be mindful of the maximum number of words. Please, be concise and objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your report in one or more cells here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### task 1\n",
    "We convert orignial graph to no direction graph and use BFS to search whether there is a path between two nodes. The complexity is O(V+E). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### task 2\n",
    "\n",
    "We use pd.groupby() method to calculate posterior marginal. The complexity is O(N^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## summay and discussin of the experimental results for task 3, 4, 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hist of  acc and stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1fffe5cba20>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare acc and stddev\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2,1)\n",
    "fig.tight_layout(pad=3.0)\n",
    "axes[0].title.set_text('acc')\n",
    "axes[1].title.set_text('stddev')\n",
    "\n",
    "\n",
    "acc_data = pd.Series([0.8411, 0.7919, 0.8374], index=['Bayesian Network', 'Naive Bayes', 'Tree-augmented Na√Øve Bayes'])\n",
    "acc_data.plot(kind = 'barh', ax=axes[0], alpha=0.7)\n",
    "axes[0].set_xlim((0.75, 0.85))\n",
    "\n",
    "\n",
    "stddev_data = pd.Series([0.006208, 0.009104, 0.006946], index=['Bayesian Network', 'Naive Bayes', 'Tree-augmented Na√Øve Bayes'])\n",
    "acc_data.plot(kind = 'barh', ax=axes[1], alpha=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian Network classifier has the highest accuracy (0.8411) among the tree classifiers and Na√Øve Bayes classifier has the lowest accuracy (0.7919).\n",
    "\n",
    "### Bayesian Network\n",
    "Given the fact that Bayesian Network represents the true relationship between every attribute, all dependencies will be calculated in the algorithm. We use Markov blanket to reduce the computation load and use join() and prob() function in tutorial to generate the joint distribution includes all variables. The complexity is O(N^2).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the chain rule for Bayesian networks, we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$P(bc,e) = \\sum P(location)P(age)P(bc|location, age)P(mass|bc, breastdensity)P(ad|bc)\\\n",
       "P(fibrtissuedev|ad)P(mc|bc)P(skinretract|bc, fibrtissuedev)P(nippledischarge|bc, fibrtissuedev)$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Latex(r'$P(bc,e) = \\sum P(location)P(age)P(bc|location, age)P(mass|bc, breastdensity)P(ad|bc)\\\n",
    "P(fibrtissuedev|ad)P(mc|bc)P(skinretract|bc, fibrtissuedev)P(nippledischarge|bc, fibrtissuedev)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Na√Øve Bayes\n",
    "\n",
    "In Na√Øve Bayes, we make a strong assumption that every two attributes are independent given the class variable. This assumption uses much less parameters compared with original Bayes Network which makes it faster to get the result. However, because it ignores the connection between attributes, the accuracy is lower. \n",
    "In NBC graph, class variable is the only parent and other attributes are children. Then we use this new graph to calculate posterior marginal. The complexity is O(N^2). In prediction part, we sum up all log probability in evidence. The complexity is O(N).\n",
    "\n",
    "The NBC graph shows bellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The chain rule of Bayesian networks\n",
    "# BC is the class variable\n",
    "# All other attributes make up the instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$P(bc,e) = \\sum \\log(P(bc))log(P(breastdensity|bc))log(P(location|bc))log(P(age|bc))\\\n",
       "log(P(mass|bc))log(P(ad|bc))log(P(mc|bc))log(P(size|bc))log(P(shape|bc))\\\n",
       "log(P(fibrtissuedev|bc))log(P(skinretract|bc))log(P(nippledischarge|bc))log(P(spiculation|bc))log(P(margin|bc))$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Latex(r\"$P(bc,e) = \\sum \\log(P(bc))log(P(breastdensity|bc))log(P(location|bc))log(P(age|bc))\\\n",
    "log(P(mass|bc))log(P(ad|bc))log(P(mc|bc))log(P(size|bc))log(P(shape|bc))\\\n",
    "log(P(fibrtissuedev|bc))log(P(skinretract|bc))log(P(nippledischarge|bc))log(P(spiculation|bc))log(P(margin|bc))$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"1328pt\" height=\"116pt\"\r\n",
       " viewBox=\"0.00 0.00 1328.49 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-112 1324.49,-112 1324.49,4 -4,4\"/>\r\n",
       "<!-- BC -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>BC</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"567.095\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"567.095\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">BC</text>\r\n",
       "</g>\r\n",
       "<!-- BreastDensity -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>BreastDensity</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"61.0946\" cy=\"-18\" rx=\"61.1893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"61.0946\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">BreastDensity</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;BreastDensity -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>BC&#45;&gt;BreastDensity</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M540.389,-86.8525C471.96,-81.1124 284.896,-63.9245 131.095,-36 125.996,-35.0742 120.714,-34.0028 115.441,-32.857\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"115.889,-29.3702 105.364,-30.5809 114.347,-36.1982 115.889,-29.3702\"/>\r\n",
       "</g>\r\n",
       "<!-- Location -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>Location</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"183.095\" cy=\"-18\" rx=\"42.7926\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"183.095\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Location</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;Location -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>BC&#45;&gt;Location</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M540.561,-86.2045C483.908,-79.9219 347.147,-63.0812 235.095,-36 231.667,-35.1716 228.14,-34.226 224.615,-33.2146\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"225.352,-29.7809 214.767,-30.2324 223.323,-36.4805 225.352,-29.7809\"/>\r\n",
       "</g>\r\n",
       "<!-- Age -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>Age</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"271.095\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"271.095\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Age</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;Age -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>BC&#45;&gt;Age</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M540.722,-85.7571C493.138,-79.4401 390.148,-63.6276 307.095,-36 305.176,-35.3619 303.226,-34.6476 301.277,-33.883\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"302.255,-30.4936 291.685,-29.759 299.49,-36.9244 302.255,-30.4936\"/>\r\n",
       "</g>\r\n",
       "<!-- Mass -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>Mass</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"347.095\" cy=\"-18\" rx=\"30.5947\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"347.095\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Mass</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;Mass -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>BC&#45;&gt;Mass</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M542.349,-82.6857C507.381,-73.5441 441.681,-55.5622 387.095,-36 384.733,-35.1536 382.31,-34.2403 379.881,-33.2917\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"381.187,-30.0445 370.605,-29.5254 378.554,-36.5303 381.187,-30.0445\"/>\r\n",
       "</g>\r\n",
       "<!-- AD -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>AD</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"423.095\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"423.095\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">AD</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;AD -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>BC&#45;&gt;AD</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M545.847,-78.6713C521.493,-66.8324 481.376,-47.3312 453.667,-33.8615\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"454.953,-30.5953 444.429,-29.3711 451.893,-36.8909 454.953,-30.5953\"/>\r\n",
       "</g>\r\n",
       "<!-- MC -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>MC</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"495.095\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"495.095\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">MC</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;MC -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>BC&#45;&gt;MC</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M552.524,-74.8345C542.345,-64.9376 528.571,-51.5462 517.064,-40.3591\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"519.5,-37.8461 509.89,-33.3847 514.621,-42.865 519.5,-37.8461\"/>\r\n",
       "</g>\r\n",
       "<!-- Size -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>Size</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"567.095\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"567.095\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Size</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;Size -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>BC&#45;&gt;Size</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M567.095,-71.6966C567.095,-63.9827 567.095,-54.7125 567.095,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"570.595,-46.1043 567.095,-36.1043 563.595,-46.1044 570.595,-46.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- Shape -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>Shape</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"645.095\" cy=\"-18\" rx=\"33.2948\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"645.095\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Shape</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;Shape -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>BC&#45;&gt;Shape</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M582.505,-75.1703C593.535,-65.2715 608.597,-51.7539 621.182,-40.4601\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"623.534,-43.0517 628.639,-33.7677 618.859,-37.842 623.534,-43.0517\"/>\r\n",
       "</g>\r\n",
       "<!-- FibrTissueDev -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>FibrTissueDev</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"760.095\" cy=\"-18\" rx=\"64.189\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"760.095\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">FibrTissueDev</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;FibrTissueDev -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>BC&#45;&gt;FibrTissueDev</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M590.375,-80.5564C620.598,-69.5946 674.066,-50.202 712.93,-36.1062\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"714.266,-39.3449 722.473,-32.645 711.879,-32.7644 714.266,-39.3449\"/>\r\n",
       "</g>\r\n",
       "<!-- SkinRetract -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>SkinRetract</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"896.095\" cy=\"-18\" rx=\"53.0913\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"896.095\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">SkinRetract</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;SkinRetract -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>BC&#45;&gt;SkinRetract</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M592.896,-84.4522C640.556,-75.9202 745.527,-56.5143 833.095,-36 837.495,-34.9692 842.053,-33.8469 846.614,-32.6866\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"847.743,-36.0096 856.541,-30.1067 845.982,-29.2346 847.743,-36.0096\"/>\r\n",
       "</g>\r\n",
       "<!-- NippleDischarge -->\r\n",
       "<g id=\"node12\" class=\"node\"><title>NippleDischarge</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1038.09\" cy=\"-18\" rx=\"70.6878\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1038.09\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">NippleDischarge</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;NippleDischarge -->\r\n",
       "<g id=\"edge11\" class=\"edge\"><title>BC&#45;&gt;NippleDischarge</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M593.749,-86.0826C657.135,-78.9936 821.762,-59.6912 958.095,-36 964.154,-34.9471 970.453,-33.7638 976.737,-32.5244\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"977.453,-35.9506 986.563,-30.5414 976.068,-29.0889 977.453,-35.9506\"/>\r\n",
       "</g>\r\n",
       "<!-- Spiculation -->\r\n",
       "<g id=\"node13\" class=\"node\"><title>Spiculation</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1178.09\" cy=\"-18\" rx=\"51.1914\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1178.09\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Spiculation</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;Spiculation -->\r\n",
       "<g id=\"edge12\" class=\"edge\"><title>BC&#45;&gt;Spiculation</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M593.998,-88.1282C674.303,-85.1599 919.054,-73.4534 1118.09,-36 1122.46,-35.1782 1126.97,-34.1829 1131.46,-33.0908\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1132.41,-36.4625 1141.22,-30.5754 1130.66,-29.6844 1132.41,-36.4625\"/>\r\n",
       "</g>\r\n",
       "<!-- Margin -->\r\n",
       "<g id=\"node14\" class=\"node\"><title>Margin</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1284.09\" cy=\"-18\" rx=\"36.2938\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1284.09\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Margin</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;Margin -->\r\n",
       "<g id=\"edge13\" class=\"edge\"><title>BC&#45;&gt;Margin</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M594.333,-89.5084C686.215,-90.663 992.715,-89.9475 1238.09,-36 1241.25,-35.3053 1244.49,-34.4423 1247.71,-33.4762\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1248.83,-36.7934 1257.22,-30.334 1246.63,-30.1465 1248.83,-36.7934\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x1fffe67bcf8>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NBC graph\n",
    "navie_Bayes_G = Digraph(comment='Naive Bayes Graph')\n",
    "\n",
    "for v in naive_graph:\n",
    "    navie_Bayes_G.node(str(v))\n",
    "\n",
    "for v in naive_graph:\n",
    "    for w in naive_graph[v]:\n",
    "        navie_Bayes_G.edge(str(v), str(w))\n",
    "    \n",
    "navie_Bayes_G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree-augmented Navie Baye\n",
    "\n",
    "In fact, most of times we do not have the real graph to show the hidden connection in all attributes. TAN helps us figure out some strong connections in data using mutual information which makes it more reasonable than Na√Øve Bayes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we calculate MI. The formula is showed as below:\n",
    "\n",
    "ùê¥ùëñ and ùê¥ùëó represent attributes of the network\n",
    "\n",
    "C represents the class variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$MI_D(A_i,A_j|C) = \\sum_{a_i,a_j,c} P_D(a_i, a_j, c)\\log(\\frac{P_D(a_i,a_j|c)}{P_D(a_i|c)P_D(a_j|c)})$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Latex(r'$MI_D(A_i,A_j|C) = \\sum_{a_i,a_j,c} P_D(a_i, a_j, c)\\log(\\frac{P_D(a_i,a_j|c)}{P_D(a_i|c)P_D(a_j|c)})$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then using MI to create the maximum spanning tree, the complexity is O(N^2).\n",
    "\n",
    "The TAN graph shows bellow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAN graph\n",
    "TAN_Bayes_G = Digraph(comment='TAN Graph')\n",
    "\n",
    "for v in tan_graph:\n",
    "    TAN_Bayes_G.node(str(v))\n",
    "\n",
    "for v in tan_graph:\n",
    "    for w in tan_graph[v]:\n",
    "        TAN_Bayes_G.edge(str(v), str(w))\n",
    "    \n",
    "TAN_Bayes_G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input the new graph into Bayesian Network to get the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
